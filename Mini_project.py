# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uruuu8buHixWg3tBkDSj6VyP6EqnXpTT
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""# Load your dataset"""

df = pd.read_csv('/content/patient_lifestyle_health.csv')

"""# Display count of missing values for each column"""

missing_values = df.isnull().sum()

missing_values[missing_values > 0]

"""# Set plot style"""

sns.set(style="whitegrid")

"""# 1. Distribution of Health Score"""

sns.histplot(df['Health_Score'], kde=True)
plt.title("Health Score Distribution")
plt.xlabel("Health Score")
plt.show()

"""# 2. GPA by Self-Esteem (Box Plot)"""

sns.boxplot(data=df, x='Smoking_Status', y='Health_Score')
plt.title("Health Score by Smoking Status")
plt.show()

"""# 4. Correlation Heatmap"""

numeric_df = df.select_dtypes(include=['float64', 'int64'])
sns.heatmap(numeric_df.corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Matrix")
plt.show()

"""# Principal Components Analysis (PCA)"""

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

"""Step 1: Select only numeric columns for PCA"""

numeric_df = df.select_dtypes(include=['float64', 'int64']).drop(columns=['Patient_ID'])

"""Step 2: Standardize the data (important for PCA)"""

scaler = StandardScaler()
scaled_data = scaler.fit_transform(numeric_df)

"""Step 3:Run PCA and Create a DataFrame with the PCA result"""

pca = PCA()
pca.fit(scaled_data)
pca_components = pca.transform(scaled_data)

"""Step 4: Scree Plot the PCA result"""

plt.figure(figsize=(8, 5))
plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')
plt.title('Cumulative Explained Variance by PCA Components')
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance')
plt.grid(True)
plt.tight_layout()
plt.show()

"""Step 6: Check explained variance"""

explained_variance = pd.DataFrame({
    'PC': [f'PC{i+1}' for i in range(len(pca.explained_variance_ratio_))],
    'Explained Variance': pca.explained_variance_ratio_,
    'Cumulative': np.cumsum(pca.explained_variance_ratio_)
})
print(explained_variance)

"""Step 7: PCA Loadings Matrix(Eigenvectors)"""

loadings = pd.DataFrame(pca.components_.T,
                        columns=[f'PC{i+1}' for i in range(len(pca.components_))],
                        index=numeric_df.columns)
print("\nüîç PCA Loadings:")
print(loadings.round(3))

explained = pca.explained_variance_ratio_
cum_explained = np.cumsum(explained)

plt.figure(figsize=(8, 5))
plt.plot(range(1, len(explained) + 1), cum_explained, marker='o', color='blue')
plt.title("Scree Plot - Cumulative Explained Variance")
plt.xlabel("Principal Component")
plt.ylabel("Cumulative Variance Explained")
plt.axhline(0.80, color='red', linestyle='--', label='80% Threshold')
plt.xticks(range(1, len(explained) + 1))
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
plt.plot(range(1, len(pca.explained_variance_ratio_) + 1),
         pca.explained_variance_ratio_, marker='o', linestyle='-')
plt.title('Scree Plot - Explained Variance per Component')
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.xticks(range(1, len(pca.explained_variance_ratio_) + 1))
plt.grid(True)
plt.tight_layout()
plt.show()

"""# Factor Analysis test(FA)"""

!pip install factor_analyzer
from sklearn.preprocessing import StandardScaler
from factor_analyzer import FactorAnalyzer, calculate_kmo, calculate_bartlett_sphericity
import matplotlib.pyplot as plt

"""Select only numeric variables"""

numeric_df = df.select_dtypes(include=['int64', 'float64']).drop(columns=['Patient_ID'])

"""Standardize the data"""

scaler = StandardScaler()
scaled_data = scaler.fit_transform(numeric_df)

"""Step 1: Bartlett‚Äôs Test"""

chi_square_value, p_value = calculate_bartlett_sphericity(scaled_data)
print(f"Bartlett‚Äôs test: œá¬≤ = {chi_square_value:.2f}, p = {p_value:.5f}")

""" Step 2: KMO Test"""

kmo_all, kmo_model = calculate_kmo(scaled_data)
print(f"KMO test: Overall KMO = {kmo_model:.2f}")

"""Step 3: Scree plot to decide number of factors"""

fa = FactorAnalyzer()
fa.fit(scaled_data)
ev, v = fa.get_eigenvalues()

plt.figure(figsize=(8,5))
plt.plot(range(1, len(ev)+1), ev, marker='o')
plt.axhline(1, color='red', linestyle='--')
plt.title('Scree Plot for Factor Analysis')
plt.xlabel('Factors')
plt.ylabel('Eigenvalue')
plt.grid(True)
plt.tight_layout()
plt.show()

fa = FactorAnalyzer(n_factors=3, rotation='varimax')
fa.fit(scaled_data)

"""Step 4: Create a DataFrame for eigenvalues and eiganvector"""

corr_matrix = np.corrcoef(scaled_data, rowvar=False)
eig_vals, eig_vecs = np.linalg.eig(corr_matrix)
eigvals_df = pd.DataFrame(eig_vals, columns=['Eigenvalue'])

eigvec_df = pd.DataFrame(eig_vecs, index=numeric_df.columns, columns=[f'EV{i+1}' for i in range(len(eig_vecs))])
print("Eigenvalues:\n")
print(eigvals_df.round(3))

print("\n Eigenvectors (first 5 components):\n")
print(eigvec_df.iloc[:, :5].round(3))

"""Step 5: FA Loadings MAtrix(Eigenvectors)"""

loadings = pd.DataFrame(fa.loadings_, index=numeric_df.columns, columns=['Factor1', 'Factor2', 'Factor3'])
print("\nFactor Loadings:\n")
print(loadings.round(3))

"""# **Discriminant Analysis Test**"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

target = 'Sleep_Quality'
predictors = ['Age', 'BMI', 'Blood_Pressure', 'Cholesterol', 'Heart_Rate', 'Health_Score']

le = LabelEncoder()
df[target] = le.fit_transform(df[target])  # e.g., Poor=0, Fair=1, Good=2

X = df[predictors]
y = df[target]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)


lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)

y_pred = lda.predict(X_test)
print("üîç Classification Report:\n")
print(classification_report(y_test, y_pred, target_names=le.classes_))

accuracy = accuracy_score(y_test, y_pred)
print(f"\n Classification Accuracy: {accuracy:.2f}")

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

for col in predictors:
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribution of {col}')
    plt.show()

corr = df[predictors].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

"""# **Canonical Correlation Analysis test**"""

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cross_decomposition import CCA
import numpy as np

X_cols = ['BMI', 'Alcohol_Use', 'Physical_Activity_Level', 'Sleep_Quality']
Y_cols = ['Blood_Pressure', 'Cholesterol', 'Health_Score', 'Heart_Rate']

X_encoded = df[X_cols].copy()
for col in ['Alcohol_Use', 'Physical_Activity_Level', 'Sleep_Quality']:
    X_encoded[col] = LabelEncoder().fit_transform(X_encoded[col])

Y = df[Y_cols].copy()

X_encoded.dropna(inplace=True)
Y = Y.loc[X_encoded.index]  # Ensure same indices

X_scaled = StandardScaler().fit_transform(X_encoded)
Y_scaled = StandardScaler().fit_transform(Y)

cca = CCA(n_components=2)
X_c, Y_c = cca.fit_transform(X_scaled, Y_scaled)

canonical_corrs = [np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1] for i in range(cca.n_components)]

print(" Canonical Correlations:")
for i, corr in enumerate(canonical_corrs):
    print(f"Canonical Correlation {i+1}: {corr:.3f}")

"""# **Structural Equation Modeling (SEM) Test**"""

!pip install semopy

from sklearn.preprocessing import LabelEncoder
from semopy import Model, semplot

df['Sleep_Quality'] = LabelEncoder().fit_transform(df['Sleep_Quality'])
df['Physical_Activity_Level'] = LabelEncoder().fit_transform(df['Physical_Activity_Level'])

df_model = df[['BMI', 'Sleep_Quality', 'Physical_Activity_Level',
               'Blood_Pressure', 'Cholesterol', 'Health_Score']].dropna()

desc = """
# Latent Variables
Lifestyle =~ BMI + Sleep_Quality + Physical_Activity_Level
Health =~ Blood_Pressure + Cholesterol + Health_Score

# Regression
Health ~ Lifestyle
"""

model = Model(desc)
model.fit(df_model)

estimates = model.inspect()
print(" SEM Path Estimates:")
print(estimates)